<video></video> <canvas></canvas> <button id="stop">🐾 Pause</button>
<button id="ghost">👻 Camera off!</button>
<button id="save">💾 Save</button> <button id="wipe">🚿 Wipe</button>
<button id="blend">🍭 Blend me up</button>
<button id="change-colours">🌈 Change up colours</button>
<script src="https://unpkg.com/face-api.js@0.16.2/dist/face-api.min.js"></script>
<script>
  let paused = false;
  let blend = false;
  let ghostMode = false;
	let randomColours = true;
	let refreshColours = false;

  var canvas = document.querySelector("canvas");
  var ctx = canvas.getContext("2d");

  const videoInput = document.querySelector("video");
  const stopButton = document.getElementById("stop");

  stopButton.onclick = () => {
    paused = !paused;
    stopButton.innerText = paused ? "😃 Paint!" : "🐾 Pause";
  };

  const ghostButton = document.getElementById("ghost");
  ghostButton.onclick = () => {
    videoInput.classList.toggle("hidden");
    ghostMode = !ghostMode;
    ghostButton.innerText = ghostMode
      ? "🎥 Camera on!"
      : "👻 Camera off!";
  };

  const saveButton = document.getElementById("save");
  saveButton.onclick = () => {
    canvas.toBlob(blob => {
      const a = document.createElement("a");
      a.href = URL.createObjectURL(blob);
      a.download = "facepaint-" + Date.now();
      a.click();
    });
  };

  const wipeButton = document.getElementById("wipe");
  wipeButton.onclick = () => {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
  };

  const blendButton = document.getElementById("blend");
  blendButton.onclick = () => {
    blend = !blend;
    blendButton.innerText = blend ? "🙅 Stop blending me" : "🍭 Blend me up";
	};
	
	const changeColoursButton = document.getElementById('change-colours');
	changeColoursButton.onclick = () => refreshColours = !refreshColours;

  async function startApp() {
    await faceapi.loadSsdMobilenetv1Model("/models");
    await faceapi.loadFaceLandmarkTinyModel("/models");
    await faceapi.loadFaceLandmarkModel("/models");

    var constraints = { video: { width: 1280, height: 720 } }; // Prefer camera resolution nearest to 1280x720.

    const getRandomChannel = () => Math.floor(Math.random() * 256);

		function* rgbGenerator() { // returns random 0-255 3 times
				yield [getRandomChannel(), getRandomChannel(), getRandomChannel()];
		}

		function* generator2() {
			const cache = {};
			let index;
			while (true) {
				if (!(index in cache)) {
					cache[index] = rgbGenerator().next().value;
				}
				index = yield cache[index]; // this does not actually assign yield cache[index] to a variable 'index'
			}
		}

		const iterator = generator2();
		iterator.next();

		let randomNosePalette = generator2();
		randomNosePalette.next();
		let randomMouthPalette = generator2();
		randomMouthPalette.next();
		let randomEyePalette = generator2();
		randomEyePalette.next();

    function makeBlendColours(colourPalette, x, y) {
      const [r, g, b] = colourPalette;
      const existingRgba = ctx.getImageData(x, y, 1, 1).data;
      const [oldR, oldG, oldB] = existingRgba.slice(0, 3);
      const newR = (oldR + r) / 2;
      const newG = (oldG + g) / 2;
      const newB = (oldB + b) / 2;
      return [newR, newG, newB];
		}

    async function drawOnFaces() {
			if (refreshColours) {
				randomNosePalette = generator2();
				randomNosePalette.next();
				randomMouthPalette = generator2();
				randomMouthPalette.next();
				randomEyePalette = generator2();
				randomEyePalette.next();
				refreshColours = false;
			}

      if (paused === false) {
        const faces = await faceapi.detectAllFaces(videoInput);
        const facesWithLandmarks = await faceapi
          .detectAllFaces(videoInput)
          .withFaceLandmarks();

        facesWithLandmarks.forEach((fancyFace, index) => {
          const mouthPoints = fancyFace.landmarks.getMouth();
          const nosePoints = fancyFace.landmarks.getNose();
          const leftEyePoints = fancyFace.landmarks.getLeftEye();
					const rightEyePoints = fancyFace.landmarks.getRightEye();

          for (nosePoint of nosePoints) {
						let r, g, b;
						if (randomColours) {
							[r,g,b] = randomNosePalette.next(index).value;
						};
						ctx.fillStyle = `rgb(${r},${g},${b})`;

            if (blend) {
              [r2, g2, b2] = makeBlendColours(
                [r, g, b],
                nosePoint.x,
                nosePoint.y
              );
              ctx.fillStyle = `rgb(${r2},${g2},${b2})`;
            };
            ctx.fillRect(nosePoint.x, nosePoint.y, 5, 5);
          }

          for (mouthPoint of mouthPoints) {
						let r, g, b;
            if (randomColours) {
							[r,g,b] = randomMouthPalette.next(index).value;
            };
            ctx.fillStyle = `rgb(${r},${g},${b})`;

            if (blend) {
              [r2, g2, b2] = makeBlendColours(
                [r, g, b],
                mouthPoint.x,
                mouthPoint.y
              );
              ctx.fillStyle = `rgb(${r2},${g2},${b2})`;
            }
            ctx.fillRect(mouthPoint.x, mouthPoint.y, 5, 5);
          }

          for (eyePoint of [...leftEyePoints, ...rightEyePoints]) {
            let r, g, b;
            if (randomColours) {
							[r,g,b] = randomEyePalette.next(index).value;
            };
            ctx.fillStyle = `rgb(${r},${g},${b})`;
            if (blend) {
              [r2, g2, b2] = makeBlendColours(
                [r, g, b],
                eyePoint.x,
                eyePoint.y
              );
              ctx.fillStyle = `rgb(${r2},${g2},${b2})`;
            };
            ctx.fillRect(eyePoint.x, eyePoint.y, 5, 5);
          }
        });
      }

      window.requestAnimationFrame(drawOnFaces); // repeat the drawOnFaces every time the browser is about to repaint
    }

    navigator.mediaDevices
      .getUserMedia(constraints)
      .then(mediaStream => {
        var video = document.querySelector("video");
        video.srcObject = mediaStream;
        video.onloadedmetadata = e => {
          console.log("in onloadedmetadata");
          video.play();
          const videoDimensions = faceapi.getMediaDimensions(video);

          canvas.width = videoDimensions.width;
					canvas.height = videoDimensions.height;
					
          drawOnFaces();
        };
        console.log("end of mediastream thingy");
      })
      .catch(err => {
        console.log(err.name + ": " + err.message);
      }); // always check for errors at the end.
  }
  startApp();
</script>
<style>
  body {
    background-color: #201c25;
  }
  video,
  canvas {
    position: absolute;
    left: 0;
    top: 0;
  }
  button {
    position: relative;
    height: 24px;
    border-radius: 5px;
  }
  .hidden {
    display: none;
  }
</style>
